{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Hello\\nAI: Hi there!'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory() # plain text\n",
    "memory.save_context({\"input\": \"Hello\"}, {\"output\": \"Hi there!\"})\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Hello\\nAI: Hi there!\\nHuman: Hello\\nAI: Hi there!\\nHuman: Hello\\nAI: Hi there!\\nHuman: Hello\\nAI: Hi there!'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.save_context({\"input\": \"Hello\"}, {\"output\": \"Hi there!\"})\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='Hello'), AIMessage(content='Hi there!')]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory = ConversationBufferMemory(return_messages=True) # chat mode \n",
    "memory.save_context({\"input\": \"Hello\"}, {\"output\": \"Hi there!\"})\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='Hello'),\n",
       "  AIMessage(content='Hi there!'),\n",
       "  HumanMessage(content='Hello'),\n",
       "  AIMessage(content='Hi there!'),\n",
       "  HumanMessage(content='Hello'),\n",
       "  AIMessage(content='Hi there!'),\n",
       "  HumanMessage(content='Hello'),\n",
       "  AIMessage(content='Hi there!'),\n",
       "  HumanMessage(content='Hello'),\n",
       "  AIMessage(content='Hi there!')]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.save_context({\"input\": \"Hello\"}, {\"output\": \"Hi there!\"})\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(\n",
    "    return_messages=True,\n",
    "    k=4, # limit to last 4 messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_message(input, output):\n",
    "    memory.save_context({\"input\": input}, {\"output\": output})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_message(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_message(2,2)\n",
    "add_message(3,3)\n",
    "add_message(4,4)\n",
    "add_message(5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='2'),\n",
       "  AIMessage(content='2'),\n",
       "  HumanMessage(content='3'),\n",
       "  AIMessage(content='3'),\n",
       "  HumanMessage(content='4'),\n",
       "  AIMessage(content='4'),\n",
       "  HumanMessage(content='5'),\n",
       "  AIMessage(content='5')]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_message(6,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='3'),\n",
       "  AIMessage(content='3'),\n",
       "  HumanMessage(content='4'),\n",
       "  AIMessage(content='4'),\n",
       "  HumanMessage(content='5'),\n",
       "  AIMessage(content='5'),\n",
       "  HumanMessage(content='6'),\n",
       "  AIMessage(content='6')]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryMemory(llm=llm)\n",
    "\n",
    "\n",
    "def add_message(input, output):\n",
    "    memory.save_context({\"input\": input}, {\"output\": output})\n",
    "\n",
    "\n",
    "def get_history():\n",
    "    return memory.load_memory_variables({})\n",
    "\n",
    "\n",
    "add_message(\"Hi I'm Hobeom, I live in South Korea\", \"Wow that is so cool!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_message(\"South Korea is so pretty\", \"I wish I could go!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Hobeom from South Korea introduces himself to the AI, who responds enthusiastically. Hobeom mentions how pretty South Korea is, and the AI expresses a wish to visit the country.'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConversationSummaryBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=150,\n",
    "    return_messages=True,\n",
    ")\n",
    "\n",
    "\n",
    "def add_message(input, output):\n",
    "    memory.save_context({\"input\": input}, {\"output\": output})\n",
    "\n",
    "\n",
    "def get_history():\n",
    "    return memory.load_memory_variables({})\n",
    "\n",
    "\n",
    "add_message(\"Hi I'm Hobeom, I live in South Korea\", \"Wow that is so cool!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_message(\"South Korea is so pretty\", \"I wish I could go!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content=\"Hi I'm Hobeom, I live in South Korea\"),\n",
       "  AIMessage(content='Wow that is so cool!'),\n",
       "  HumanMessage(content='South Korea is so pretty'),\n",
       "  AIMessage(content='I wish I could go!!!')]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The distance between Korea and the US varies depending on the specific locations being compared. For example, the distance between Seoul, South Korea and Los Angeles, California is approximately 6,000 miles (9,656 kilometers) when measured in a straight line. However, the distance can be longer or shorter depending on the specific cities being compared and the mode of transportation used.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.predict(\"How far is Korea from the US\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_message(\"How far is Korea from the US\", \"The distance between Korea and the US varies depending on the specific locations being compared. For example, the distance between Seoul, South Korea and Los Angeles, California is approximately 6,000 miles (9,656 kilometers) when measured in a straight line. However, the distance can be longer or shorter depending on the specific cities being compared and the mode of transportation used.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content=\"Hi I'm Hobeom, I live in South Korea\"),\n",
       "  AIMessage(content='Wow that is so cool!'),\n",
       "  HumanMessage(content='South Korea is so pretty'),\n",
       "  AIMessage(content='I wish I could go!!!'),\n",
       "  HumanMessage(content='How far is Korea from the US?'),\n",
       "  AIMessage(content='The distance between Korea and the US varies depending on the specific locations being compared. For example, the distance between Seoul, South Korea and Los Angeles, California is approximately 6,000 miles (9,656 kilometers) when measured in a straight line. However, the distance can be longer or shorter depending on the specific cities being compared and the mode of transportation used.')]}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Korea is approximately 2,000 miles (3,218 kilometers) away from the Himalayas.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.predict(\"How far is Korea from the Himalayas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_message(\"How far is Korea from the Himalayas\", 'Korea is approximately 2,000 miles (3,218 kilometers) away from the Himalayas.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [SystemMessage(content='The human introduces themselves as Hobeom from South Korea. The AI expresses admiration for this and the human mentions how beautiful South Korea is.'),\n",
       "  AIMessage(content='I wish I could go!!!'),\n",
       "  HumanMessage(content='How far is Korea from the US?'),\n",
       "  AIMessage(content='The distance between Korea and the US varies depending on the specific locations being compared. For example, the distance between Seoul, South Korea and Los Angeles, California is approximately 6,000 miles (9,656 kilometers) when measured in a straight line. However, the distance can be longer or shorter depending on the specific cities being compared and the mode of transportation used.'),\n",
       "  HumanMessage(content='How far is Korea from the Himalayas?'),\n",
       "  AIMessage(content='Korea is approximately 2,000 miles (3,218 kilometers) away from the Himalayas.')]}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConversationKGMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationKGMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationKGMemory(\n",
    "    llm=llm,\n",
    "    return_messages=True,\n",
    ")\n",
    "\n",
    "\n",
    "def add_message(input, output):\n",
    "    memory.save_context({\"input\": input}, {\"output\": output})\n",
    "\n",
    "\n",
    "add_message(\"Hi I'm HoBeom, I live in South Korea\", \"Wow that is so cool!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [SystemMessage(content='On HoBeom: HoBeom lives in South Korea.')]}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({\"inputs\": \"Who is HoBeom\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_message(\"HoBeom likes pizza\", \"Wow that is so cool!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [SystemMessage(content='On HoBeom: HoBeom lives in South Korea. HoBeom likes pizza.')]}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({\"inputs\": \"What dose hobeom like?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory on LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    You are a helpful AI talking to a human.\n",
      "\n",
      "    \n",
      "    Human:My name is HoBeom\n",
      "    You:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello HoBeom! How can I assist you today?'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=120,\n",
    "    memory_key=\"chat_history\",\n",
    ")\n",
    "\n",
    "template = \"\"\"\n",
    "    You are a helpful AI talking to a human.\n",
    "\n",
    "    {chat_history}\n",
    "    Human:{question}\n",
    "    You:\n",
    "\"\"\"\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    prompt=PromptTemplate.from_template(template),\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "chain.predict(question=\"My name is HoBeom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    You are a helpful AI talking to a human.\n",
      "\n",
      "    Human: My name is HoBeom\n",
      "AI: Hello HoBeom! How can I assist you today?\n",
      "    Human:I like pizza\n",
      "    You:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"That's great to hear! Pizza is a popular choice for many people. Is there a specific type of pizza you enjoy or are you looking for recommendations?\""
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question=\"I like pizza\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    You are a helpful AI talking to a human.\n",
      "\n",
      "    Human: My name is HoBeom\n",
      "AI: Hello HoBeom! How can I assist you today?\n",
      "Human: I like pizza\n",
      "AI: That's great to hear! Pizza is a popular choice for many people. Is there a specific type of pizza you enjoy or are you looking for recommendations?\n",
      "    Human:I live in Deajeon\n",
      "    You:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"That's interesting! Daejeon is a beautiful city in South Korea. Is there anything specific you would like to know or talk about regarding Daejeon?\""
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question=\"I live in Deajeon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    You are a helpful AI talking to a human.\n",
      "\n",
      "    System: The human introduces themselves as HoBeom.\n",
      "AI: Hello HoBeom! How can I assist you today?\n",
      "Human: I like pizza\n",
      "AI: That's great to hear! Pizza is a popular choice for many people. Is there a specific type of pizza you enjoy or are you looking for recommendations?\n",
      "Human: I live in Deajeon\n",
      "AI: That's interesting! Daejeon is a beautiful city in South Korea. Is there anything specific you would like to know or talk about regarding Daejeon?\n",
      "    Human:What do I like?\n",
      "    You:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm not sure what you like specifically, but based on what you've mentioned so far, it seems like you enjoy pizza and live in Daejeon. Is there anything else you'd like to share about your preferences or interests?\""
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question=\"What do I like?\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': \"System: HoBeom introduces themselves to the AI. The AI greets HoBeom and asks how it can assist. HoBeom shares their love for pizza, and the AI acknowledges this, asking if there is a specific type of pizza they enjoy or if they need recommendations.\\nHuman: I live in Deajeon\\nAI: That's interesting! Daejeon is a beautiful city in South Korea. Is there anything specific you would like to know or talk about regarding Daejeon?\\nHuman: What do I like?\\nAI: I'm not sure what you like specifically, but based on what you've mentioned so far, it seems like you enjoy pizza and live in Daejeon. Is there anything else you'd like to share about your preferences or interests?\"}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat Based Memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a helpful AI talking to a human\n",
      "Human: My name is HoBeom\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello HoBeom! How can I assist you today?'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=120,\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True,\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful AI talking to a human\"),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "chain.predict(question=\"My name is HoBeom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='My name is HoBeom'),\n",
       "  AIMessage(content='Hello HoBeom! How can I assist you today?')]}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a helpful AI talking to a human\n",
      "Human: My name is HoBeom\n",
      "AI: Hello HoBeom! How can I assist you today?\n",
      "Human: I like pizza\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Pizza is a popular choice! What toppings do you usually like on your pizza, HoBeom?'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question=\"I like pizza\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a helpful AI talking to a human\n",
      "Human: My name is HoBeom\n",
      "AI: Hello HoBeom! How can I assist you today?\n",
      "Human: I like pizza\n",
      "AI: Pizza is a popular choice! What toppings do you usually like on your pizza, HoBeom?\n",
      "Human: I live in Deajeon\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Daejeon is a beautiful city in South Korea! What do you enjoy most about living there, HoBeom?'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question=\"I live in Deajeon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a helpful AI talking to a human\n",
      "Human: My name is HoBeom\n",
      "AI: Hello HoBeom! How can I assist you today?\n",
      "Human: I like pizza\n",
      "AI: Pizza is a popular choice! What toppings do you usually like on your pizza, HoBeom?\n",
      "Human: I live in Deajeon\n",
      "AI: Daejeon is a beautiful city in South Korea! What do you enjoy most about living there, HoBeom?\n",
      "Human: What is my name?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your name is HoBeom. How can I assist you further, HoBeom?'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LCEL Based Memory \n",
    "* expose memory chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=120,\n",
    "    return_messages=True,\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful AI talking to a human\"),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def load_memory(_):\n",
    "    return memory.load_memory_variables({})[\"history\"]\n",
    "\n",
    "\n",
    "chain = RunnablePassthrough.assign(history=load_memory) | prompt | llm\n",
    "\n",
    "\n",
    "def invoke_chain(question):\n",
    "    result = chain.invoke({\"question\": question})\n",
    "    memory.save_context(\n",
    "        {\"input\": question},\n",
    "        {\"output\": result.content},\n",
    "    )\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Nice to meet you, HoBeom! How can I assist you today?'\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"My name is HoBeom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Pizza is a popular choice! What toppings do you usually like on your pizza, HoBeom?'\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"I like pizza\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"That's interesting to know, HoBeom! Is there anything specific you'd like to know or talk about regarding Daejeon or anything else?\"\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"I live in Deajeon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Your name is HoBeom.'\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"What is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='You mentioned earlier that you like pizza. Is there anything else you enjoy or would like to talk about, HoBeom?'\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"What do I like?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Responses:\n",
      "ğŸ›©ï¸ğŸ‘¨â€âœˆï¸ğŸ”¥\n",
      "ğŸ‘¨â€ğŸ‘¨â€ğŸ‘¦ğŸ”«ğŸ\n",
      "ğŸŒ¿ğŸŒŒğŸª\n",
      "ğŸ¦ˆğŸŒŠğŸš¤\n",
      "\n",
      "Memory Content:\n",
      "Human: Top Gun\n",
      "Ai: ğŸ›©ï¸ğŸ‘¨â€âœˆï¸ğŸ”¥\n",
      "Human: The Godfather\n",
      "Ai: ğŸ‘¨â€ğŸ‘¨â€ğŸ‘¦ğŸ”«ğŸ\n",
      "Human: Avatar\n",
      "Ai: ğŸŒ¿ğŸŒŒğŸª\n",
      "Human: Jaws\n",
      "Ai: ğŸ¦ˆğŸŒŠğŸš¤\n",
      "\n",
      "Ask about the first question again:\n",
      "ğŸ›©ï¸ğŸ‘¨â€âœˆï¸ğŸ”¥\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ğŸ›©ï¸ğŸ‘¨\\u200dâœˆï¸ğŸ”¥'"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import FewShotChatMessagePromptTemplate, ChatPromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "chat_examples = [\n",
    "    {\"input\": \"Top Gun\", \"output\": \"ğŸ›©ï¸ğŸ‘¨â€âœˆï¸ğŸ”¥\"},\n",
    "    {\"input\": \"The Godfather\", \"output\": \"ğŸ‘¨â€ğŸ‘¨â€ğŸ‘¦ğŸ”«ğŸ\"},\n",
    "    {\"input\": \"Frozen\", \"output\": \"â„ï¸ğŸ‘©â€â¤ï¸â€ğŸ‘©â›„\"},\n",
    "    {\"input\": \"Inception\", \"output\": \"ğŸ’¤ğŸŒ€ğŸ’¡\"},\n",
    "]\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    examples=chat_examples,\n",
    "    example_prompt=example_prompt,\n",
    "    input_variables=[\"question\"],\n",
    ")\n",
    "\n",
    "system_message = (\n",
    "    \"You must respond to each movie name with exactly three emojis that represent the movie. \"\n",
    "    \"If the movie has been mentioned before in the conversation history, you must return the same emojis as before. \"\n",
    "    \"Consistency is crucial for already mentioned movies.\"\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_message),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "chain = LLMChain(\n",
    "    prompt=final_prompt,\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    ")\n",
    "\n",
    "def invoke_chain(question):\n",
    "    response = chain.run({\"question\": question})\n",
    "    print(response)\n",
    "    return response\n",
    "\n",
    "print(\"Test Responses:\")\n",
    "invoke_chain(\"Top Gun\")\n",
    "invoke_chain(\"The Godfather\")\n",
    "invoke_chain(\"Avatar\")\n",
    "invoke_chain(\"Jaws\")\n",
    "\n",
    "print(\"\\nMemory Content:\")\n",
    "for message in memory.chat_memory.messages:\n",
    "    print(f\"{message.type.capitalize()}: {message.content}\")\n",
    "\n",
    "print(\"\\nAsk about the first question again:\")\n",
    "invoke_chain(\"What was the first movie I asked about?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ›©ï¸ğŸ‘¨â€âœˆï¸ğŸ”¥\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ğŸ›©ï¸ğŸ‘¨\\u200dâœˆï¸ğŸ”¥'"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invoke_chain(\"What was the first movie I asked about?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‘¨â€ğŸ‘¨â€ğŸ‘¦ğŸ”«ğŸ\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ğŸ‘¨\\u200dğŸ‘¨\\u200dğŸ‘¦ğŸ”«ğŸ'"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invoke_chain(\"What was the second movie I asked about?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â„ï¸ğŸ‘©â€â¤ï¸â€ğŸ‘©â›„\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'â„ï¸ğŸ‘©\\u200dâ¤ï¸\\u200dğŸ‘©â›„'"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invoke_chain(\"What was the third movie I asked about?\") # Fail Avatar -> Frozen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You asked about \"Frozen.\" â„ï¸ğŸ‘©â€â¤ï¸â€ğŸ‘©â›„\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'You asked about \"Frozen.\" â„ï¸ğŸ‘©\\u200dâ¤ï¸\\u200dğŸ‘©â›„'"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invoke_chain(\"What was the fourth movie I asked about?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Memory Content:\n",
      "Human: Top Gun\n",
      "Ai: ğŸ›©ï¸ğŸ‘¨â€âœˆï¸ğŸ”¥\n",
      "Human: The Godfather\n",
      "Ai: ğŸ‘¨â€ğŸ‘¨â€ğŸ‘¦ğŸ”«ğŸ\n",
      "Human: Avatar\n",
      "Ai: ğŸŒ¿ğŸŒŒğŸ’™\n",
      "Human: Jaws\n",
      "Ai: ğŸ¦ˆğŸŒŠğŸš¤\n",
      "Human: What was the first movie I asked about?\n",
      "Ai: ğŸ›©ï¸ğŸ‘¨â€âœˆï¸ğŸ”¥\n",
      "Human: What was the first movie I asked about?\n",
      "Ai: ğŸ›©ï¸ğŸ‘¨â€âœˆï¸ğŸ”¥\n",
      "Human: What was the second movie I asked about?\n",
      "Ai: ğŸ‘¨â€ğŸ‘¨â€ğŸ‘¦ğŸ”«ğŸ\n",
      "Human: What was the third movie I asked about?\n",
      "Ai: â„ï¸ğŸ‘©â€â¤ï¸â€ğŸ‘©â›„\n",
      "Human: What was the fourth movie I asked about?\n",
      "Ai: You asked about \"Frozen.\" â„ï¸ğŸ‘©â€â¤ï¸â€ğŸ‘©â›„\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMemory Content:\")\n",
    "for message in memory.chat_memory.messages:\n",
    "    print(f\"{message.type.capitalize()}: {message.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['question'] messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You must respond to each movie name with exactly three emojis that represent the movie. If the movie has been mentioned before in the conversation history, you must return the same emojis as before. ')), FewShotChatMessagePromptTemplate(examples=[{'input': 'Top Gun', 'output': 'ğŸ›©ï¸ğŸ‘¨\\u200dâœˆï¸ğŸ”¥'}, {'input': 'The Godfather', 'output': 'ğŸ‘¨\\u200dğŸ‘¨\\u200dğŸ‘¦ğŸ”«ğŸ'}, {'input': 'Frozen', 'output': 'â„ï¸ğŸ‘©\\u200dâ¤ï¸\\u200dğŸ‘©â›„'}, {'input': 'Inception', 'output': 'ğŸ’¤ğŸŒ€ğŸ’¡'}], input_variables=['question'], example_prompt=ChatPromptTemplate(input_variables=['input', 'output'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=['output'], template='{output}'))])), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], template='{question}'))]\n"
     ]
    }
   ],
   "source": [
    "print(final_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸŒ¿ğŸŒŒğŸ’™\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ğŸŒ¿ğŸŒŒğŸ’™'"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invoke_chain(\"Avatar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ›©ï¸ğŸ‘¨â€âœˆï¸ğŸ”¥\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ğŸ›©ï¸ğŸ‘¨\\u200dâœˆï¸ğŸ”¥'"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invoke_chain(\"Top Gun\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¦ˆğŸŠâ€â™‚ï¸ğŸ¦·\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ğŸ¦ˆğŸŠ\\u200dâ™‚ï¸ğŸ¦·'"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invoke_chain(\"Jaws\") # fail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GPT-4o-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Responses:\n",
      "âœˆï¸ğŸ˜ğŸ”¥\n",
      "ğŸ‘”ğŸğŸ”«\n",
      "ğŸŒŒğŸ‘½ğŸŒ±\n",
      "ğŸ¦ˆğŸŒŠğŸš¤\n",
      "\n",
      "Memory Content:\n",
      "Human: Top Gun\n",
      "Ai: âœˆï¸ğŸ˜ğŸ”¥\n",
      "Human: The Godfather\n",
      "Ai: ğŸ‘”ğŸğŸ”«\n",
      "Human: Avatar\n",
      "Ai: ğŸŒŒğŸ‘½ğŸŒ±\n",
      "Human: Jaws\n",
      "Ai: ğŸ¦ˆğŸŒŠğŸš¤\n",
      "\n",
      "Ask about the first question again:\n",
      "The first movie you asked about was Frozen. â„ï¸ğŸ‘©â€â¤ï¸â€ğŸ‘©â›„\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The first movie you asked about was Frozen. â„ï¸ğŸ‘©\\u200dâ¤ï¸\\u200dğŸ‘©â›„'"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import FewShotChatMessagePromptTemplate, ChatPromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "chat_examples = [\n",
    "    {\"input\": \"Top Gun\", \"output\": \"ğŸ›©ï¸ğŸ‘¨â€âœˆï¸ğŸ”¥\"},\n",
    "    {\"input\": \"The Godfather\", \"output\": \"ğŸ‘¨â€ğŸ‘¨â€ğŸ‘¦ğŸ”«ğŸ\"},\n",
    "    {\"input\": \"Frozen\", \"output\": \"â„ï¸ğŸ‘©â€â¤ï¸â€ğŸ‘©â›„\"},\n",
    "    {\"input\": \"Inception\", \"output\": \"ğŸ’¤ğŸŒ€ğŸ’¡\"},\n",
    "]\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"assistant\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    examples=chat_examples,\n",
    "    example_prompt=example_prompt,\n",
    "    input_variables=[\"question\"],\n",
    ")\n",
    "\n",
    "system_message = (\n",
    "    \"You must respond to each movie name with exactly three emojis that represent the movie. \"\n",
    "    \"If the movie has been mentioned before in the conversation history, you must return the same emojis as before. \"\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_message),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.8, model=\"gpt-4o-mini\")\n",
    "chain = LLMChain(\n",
    "    prompt=final_prompt,\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    ")\n",
    "\n",
    "def invoke_chain(question):\n",
    "    response = chain.run({\"question\": question})\n",
    "    print(response)\n",
    "    return response\n",
    "\n",
    "print(\"Test Responses:\")\n",
    "invoke_chain(\"Top Gun\")\n",
    "invoke_chain(\"The Godfather\")\n",
    "invoke_chain(\"Avatar\")\n",
    "invoke_chain(\"Jaws\")\n",
    "\n",
    "print(\"\\nMemory Content:\")\n",
    "for message in memory.chat_memory.messages:\n",
    "    print(f\"{message.type.capitalize()}: {message.content}\")\n",
    "\n",
    "print(\"\\nAsk about the first question again:\")\n",
    "invoke_chain(\"What was the first movie I asked about?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The second movie you asked about was \"Inception.\"\n",
      "The third movie you asked about is \"Inception.\" The emojis for it are: ğŸ’¤ğŸŒ€ğŸ’¡\n",
      "You have only mentioned three movies: Frozen, Inception, and one other.\n",
      "You have only mentioned three movies so far: Frozen, Inception, and no fifth movie.\n",
      "\n",
      "Memory Content:\n",
      "Human: Top Gun\n",
      "Ai: âœˆï¸ğŸ˜ğŸ”¥\n",
      "Human: The Godfather\n",
      "Ai: ğŸ‘”ğŸğŸ”«\n",
      "Human: Avatar\n",
      "Ai: ğŸŒŒğŸ‘½ğŸŒ±\n",
      "Human: Jaws\n",
      "Ai: ğŸ¦ˆğŸŒŠğŸš¤\n",
      "Human: What was the first movie I asked about?\n",
      "Ai: The first movie you asked about was Frozen. â„ï¸ğŸ‘©â€â¤ï¸â€ğŸ‘©â›„\n",
      "Human: What was the second movie I asked about?\n",
      "Ai: The second movie you asked about was \"Inception.\"\n",
      "Human: What was the third movie I asked about?\n",
      "Ai: The third movie you asked about is \"Inception.\" The emojis for it are: ğŸ’¤ğŸŒ€ğŸ’¡\n",
      "Human: What was the fourth movie I asked about?\n",
      "Ai: You have only mentioned three movies: Frozen, Inception, and one other.\n",
      "Human: What was the fifth movie I asked about?\n",
      "Ai: You have only mentioned three movies so far: Frozen, Inception, and no fifth movie.\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"What was the second movie I asked about?\")\n",
    "invoke_chain(\"What was the third movie I asked about?\")\n",
    "invoke_chain(\"What was the fourth movie I asked about?\")\n",
    "invoke_chain(\"What was the fifth movie I asked about?\")\n",
    "\n",
    "print(\"\\nMemory Content:\")\n",
    "for message in memory.chat_memory.messages:\n",
    "    print(f\"{message.type.capitalize()}: {message.content}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Gun:ğŸ›©ï¸ğŸ‘¨â€âœˆï¸ğŸ”¥\n",
      "\n",
      "The Godfather:ğŸ‘¨â€ğŸ‘¨â€ğŸ‘¦ğŸ”«ğŸ\n",
      "\n",
      "Frozen:â„ï¸ğŸ‘©â€â¤ï¸â€ğŸ‘©â›„\n",
      "\n",
      "Inception:ğŸ’¤ğŸŒ€ğŸ’¡\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "examples = [\n",
    "    {\"input\": \"Top Gun\", \"output\": \"ğŸ›©ï¸ğŸ‘¨â€âœˆï¸ğŸ”¥\"},\n",
    "    {\"input\": \"The Godfather\", \"output\": \"ğŸ‘¨â€ğŸ‘¨â€ğŸ‘¦ğŸ”«ğŸ\"},\n",
    "    {\"input\": \"Frozen\", \"output\": \"â„ï¸ğŸ‘©â€â¤ï¸â€ğŸ‘©â›„\"},\n",
    "    {\"input\": \"Inception\", \"output\": \"ğŸ’¤ğŸŒ€ğŸ’¡\"},\n",
    "]\n",
    "\n",
    "example_prompt = PromptTemplate.from_template(\"{input}:{output}\")\n",
    "\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    input_variables=[\"question\"],\n",
    "    suffix=\"\\n\\n\",\n",
    ")\n",
    "print(few_shot_prompt.format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Responses:\n",
      "ğŸ›©ï¸ğŸ‘¨â€âœˆï¸ğŸ”¥\n",
      "ğŸ‘¨â€ğŸ‘¨â€ğŸ‘¦ğŸ”«ğŸ\n",
      "ğŸŒ¿ğŸŒŒğŸ’™\n",
      "ğŸ¦ˆğŸ–ï¸ğŸš¤\n",
      "\n",
      "Memory Content:\n",
      "Human: Top Gun\n",
      "Ai: ğŸ›©ï¸ğŸ‘¨â€âœˆï¸ğŸ”¥\n",
      "Human: The Godfather\n",
      "Ai: ğŸ‘¨â€ğŸ‘¨â€ğŸ‘¦ğŸ”«ğŸ\n",
      "Human: Avatar\n",
      "Ai: ğŸŒ¿ğŸŒŒğŸ’™\n",
      "Human: Jaws\n",
      "Ai: ğŸ¦ˆğŸ–ï¸ğŸš¤\n",
      "\n",
      "Ask about the first question again:\n",
      "ğŸ›©ï¸ğŸ‘¨â€âœˆï¸ğŸ”¥\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ğŸ›©ï¸ğŸ‘¨\\u200dâœˆï¸ğŸ”¥'"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import FewShotPromptTemplate, PromptTemplate, ChatPromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.prompts import MessagesPlaceholder\n",
    "\n",
    "examples = [\n",
    "    {\"input\": \"Top Gun\", \"output\": \"ğŸ›©ï¸ğŸ‘¨â€âœˆï¸ğŸ”¥\"},\n",
    "    {\"input\": \"The Godfather\", \"output\": \"ğŸ‘¨â€ğŸ‘¨â€ğŸ‘¦ğŸ”«ğŸ\"},\n",
    "    {\"input\": \"Frozen\", \"output\": \"â„ï¸ğŸ‘©â€â¤ï¸â€ğŸ‘©â›„\"},\n",
    "    {\"input\": \"Inception\", \"output\": \"ğŸ’¤ğŸŒ€ğŸ’¡\"},\n",
    "]\n",
    "\n",
    "example_prompt = PromptTemplate.from_template(\"{input}: {output}\")\n",
    "\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    input_variables=[],\n",
    "    suffix=\"\\n\\n\",\n",
    ")\n",
    "\n",
    "system_message = (\n",
    "    \"You must respond to each movie name with exactly three emojis that represent the movie. \"\n",
    "    \"If the movie has been mentioned before in the conversation history, you must return the same emojis as before.\\n\\n\"\n",
    "    \"Examples:\\n\"\n",
    "    f\"{few_shot_prompt.format()}\\n\\n\"\n",
    "    \"History:\\n{chat_history}\"\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=True, memory_key=\"chat_history\")\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_message),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),  # íˆìŠ¤í† ë¦¬ë¥¼ ë©”ëª¨ë¦¬ì—ì„œ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "def load_memory(_):\n",
    "    return memory.load_memory_variables({})[\"chat_history\"]\n",
    "\n",
    "chain = RunnablePassthrough.assign(chat_history=load_memory) | final_prompt | llm\n",
    "\n",
    "def invoke_chain(question):\n",
    "    response = chain.invoke({\"question\": question})\n",
    "    memory.save_context({\"input\": question}, {\"output\": response.content})\n",
    "    print(response.content)\n",
    "    # return response.content\n",
    "\n",
    "print(\"Test Responses:\")\n",
    "invoke_chain(\"Top Gun\")       # ğŸ›©ï¸ğŸ‘¨â€âœˆï¸ğŸ”¥\n",
    "invoke_chain(\"The Godfather\") # ğŸ‘¨â€ğŸ‘¨â€ğŸ‘¦ğŸ”«ğŸ\n",
    "invoke_chain(\"Avatar\")        # ğŸŒŒğŸ‰ğŸ›¡ï¸\n",
    "invoke_chain(\"Jaws\")          # ğŸ¦ˆğŸš¤ğŸŒŠ\n",
    "\n",
    "print(\"\\nMemory Content:\")\n",
    "for message in memory.chat_memory.messages:\n",
    "    print(f\"{message.type.capitalize()}: {message.content}\")\n",
    "\n",
    "print(\"\\nAsk about the first question again:\")\n",
    "invoke_chain(\"What was the first movie I asked about?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸŒ¿ğŸŒŒğŸ’™\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ğŸŒ¿ğŸŒŒğŸ’™'"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invoke_chain(\"What was the third movie I asked about?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¦ˆğŸ–ï¸ğŸš¤\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ğŸ¦ˆğŸ–ï¸ğŸš¤'"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invoke_chain(\"What was the fourth movie I asked about?\") # âœ…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¤ğŸŒ€ğŸ’¡\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ğŸ’¤ğŸŒ€ğŸ’¡'"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invoke_chain(\"inception\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ ğŸª³ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ğŸ ğŸª³ğŸ‘¨\\u200dğŸ‘©\\u200dğŸ‘§\\u200dğŸ‘¦'"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invoke_chain(\"ê¸°ìƒì¶©\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â„ï¸ğŸ‘©â€â¤ï¸â€ğŸ‘©â›„\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'â„ï¸ğŸ‘©\\u200dâ¤ï¸\\u200dğŸ‘©â›„'"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invoke_chain(\"Frozen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‘¨â€ğŸ‘¨â€ğŸ‘¦ğŸ”«ğŸ\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ğŸ‘¨\\u200dğŸ‘¨\\u200dğŸ‘¦ğŸ”«ğŸ'"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invoke_chain(\"The Godfather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¤ğŸŒ€ğŸ’¡\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ğŸ’¤ğŸŒ€ğŸ’¡'"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invoke_chain(\"Inception\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ›©ï¸ğŸ‘¨â€âœˆï¸ğŸ”¥\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ğŸ›©ï¸ğŸ‘¨\\u200dâœˆï¸ğŸ”¥'"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invoke_chain(\"What was the first movie I asked about?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¦ˆğŸ–ï¸ğŸš¤\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ğŸ¦ˆğŸ–ï¸ğŸš¤'"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invoke_chain(\"What was the seventh movie I asked about?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Top Gun\n",
      "Ai: ğŸ›©ï¸ğŸ‘¨â€âœˆï¸ğŸ”¥\n",
      "Human: The Godfather\n",
      "Ai: ğŸ‘¨â€ğŸ‘¨â€ğŸ‘¦ğŸ”«ğŸ\n",
      "Human: Avatar\n",
      "Ai: ğŸŒ¿ğŸŒŒğŸ’™\n",
      "Human: Jaws\n",
      "Ai: ğŸ¦ˆğŸ–ï¸ğŸš¤\n",
      "Human: What was the first movie I asked about?\n",
      "Ai: ğŸ›©ï¸ğŸ‘¨â€âœˆï¸ğŸ”¥\n",
      "Human: What was the third movie I asked about?\n",
      "Ai: ğŸŒ¿ğŸŒŒğŸ’™\n",
      "Human: What was the fourth movie I asked about?\n",
      "Ai: ğŸ¦ˆğŸ–ï¸ğŸš¤\n",
      "Human: inception\n",
      "Ai: ğŸ’¤ğŸŒ€ğŸ’¡\n",
      "Human: ê¸°ìƒì¶©\n",
      "Ai: ğŸ ğŸª³ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦\n",
      "Human: Frozen\n",
      "Ai: â„ï¸ğŸ‘©â€â¤ï¸â€ğŸ‘©â›„\n",
      "Human: The Godfather\n",
      "Ai: ğŸ‘¨â€ğŸ‘¨â€ğŸ‘¦ğŸ”«ğŸ\n",
      "Human: Inception\n",
      "Ai: ğŸ’¤ğŸŒ€ğŸ’¡\n",
      "Human: What was the first movie I asked about?\n",
      "Ai: ğŸ›©ï¸ğŸ‘¨â€âœˆï¸ğŸ”¥\n",
      "Human: What was the seventh movie I asked about?\n",
      "Ai: ğŸ¦ˆğŸ–ï¸ğŸš¤\n"
     ]
    }
   ],
   "source": [
    "for message in memory.chat_memory.messages:\n",
    "    print(f\"{message.type.capitalize()}: {message.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
